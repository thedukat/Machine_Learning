<<<<<<< HEAD
n1 <- n2 <- 100
x1 <- 4  ##treated
x2 <- 6  ##placebo
s1 <- 0.5  ##treated
s2 <- 2  ##placebo
sp = sqrt( ((n1-1) * s1^2) + ((n2-1) * s2^2) / (n1 + n2 - 2))
x2 - x1 + c(-1,1) * qt(.95, (n1 + n2 -2)) * sp * (1 / n1 + 1 / n2)^.5
n1 <- n2 <- 9
x1 <- 1  ##treated
x2 <- -3  ##placebo
s1 <- 1.8  ##treated
s2 <- 1.5  ##placebo
sp = sqrt( ((n1-1) * s1^2) + ((n2-1) * s2^2) / (n1 + n2 - 2))
x2 - x1 + c(-1,1) * qt(.95, (n1 + n2 -2)) * sp * (1 / n1 + 1 / n2)^.5
n1 <- n2 <- 9
x1 <- 1  ##treated
x2 <- -3  ##placebo
s1 <- 1.8  ##treated
s2 <- 1.5  ##placebo
sp = sqrt( ((n1-1) * s1^2) + ((n2-1) * s2^2) / (n1 + n2 - 2))
x2 - x1 + c(-1,1) * qt(.9, (n1 + n2 -2)) * sp * (1 / n1 + 1 / n2)^.5
n1 <- n2 <- 9
x1 <- -3  ##treated
x2 <- 1  ##placebo
s1 <- 1.5  ##treated
s2 <- 1.8  ##placebo
sp = sqrt( ((n1-1) * s1^2) + ((n2-1) * s2^2) / (n1 + n2 - 2))
x2 - x1 + c(-1,1) * qt(.9, (n1 + n2 -2)) * sp * (1 / n1 + 1 / n2)^.5
n1 <- n2 <- 9
x1 <- 1  ##treated
x2 <- -3  ##placebo
s1 <- 1.8  ##treated
s2 <- 1.5  ##placebo
sp = sqrt( ((n1-1) * s1^2) + ((n2-1) * s2^2) / (n1 + n2 - 2))
x2 - x1 + c(-1,1) * qt(.9, (n1 + n2 -2)) * sp * (1 / n1 + 1 / n2)^.5
n1 <- n2 <- 9
x1 <- 1  ##treated
x2 <- -3  ##placebo
s1 <- 1.8  ##treated
s2 <- 1.5  ##placebo
sp = sqrt( ((n1-1) * s1) + ((n2-1) * s2) / (n1 + n2 - 2))
x2 - x1 + c(-1,1) * qt(.9, (n1 + n2 -2)) * sp * (1 / n1 + 1 / n2)^.5
n1 <- n2 <- 9
x1 <- 1  ##treated
x2 <- -3  ##placebo
s1 <- 1.8  ##treated
s2 <- 1.5  ##placebo
sp = sqrt( ((n1-1) * s1) + ((n2-1) * s2) / (n1 + n2 - 2))
x2 - x1 + c(-1,1) * qt(.9, (n1 + n2 -2)) * sp * (1 / n1 + 1 / n2)^.5
mn = 1100
s = 30
n = 9
mn + c(-1, 1) * qt(.95, n-1) * s / sqrt(n)
a <- 1100
s <- 30
n <- 9
error <- qt(0.975,df=n-1)*s/sqrt(n)
left <- a-error
right <- a+error
left
right
round(left)
round(right)
n1 <- n2 <- 10
x1 <- 5 ##treated
x2 <- 6  ##placebo
s1 <- 0.68  ##treated
s2 <- 0.60  ##placebo
sp = sqrt( ((n1-1) * s1) + ((n2-1) * s2) / (n1 + n2 - 2))
x2 - x1 + c(-1,1) * qt(.9, (n1 + n2 -2)) * sp * (1 / n1 + 1 / n2)^.5
n1 <- n2 <- 10
x1 <- 5 ##treated
x2 <- 6  ##placebo
s1 <- 0.68  ##treated
s2 <- 0.60  ##placebo
sp = sqrt( ((n1-1) * s1) + ((n2-1) * s2) / (n1 + n2 - 2))
x2 - x1 + c(-1,1) * qt(.95, (n1 + n2 -2)) * sp * (1 / n1 + 1 / n2)^.5
n1 <- n2 <- 10
x1 <- 6 ##treated
x2 <- 5  ##placebo
s1 <- 0.60  ##treated
s2 <- 0.68  ##placebo
sp = sqrt( ((n1-1) * s1) + ((n2-1) * s2) / (n1 + n2 - 2))
x2 - x1 + c(-1,1) * qt(.95, (n1 + n2 -2)) * sp * (1 / n1 + 1 / n2)^.5
n1 <- n2 <- 10
x1 <- 5 ##treated
x2 <- 3  ##placebo
s1 <- 0.68  ##treated
s2 <- 0.60  ##placebo
sp = sqrt( ((n1-1) * s1) + ((n2-1) * s2) / (n1 + n2 - 2))
x2 - x1 + c(-1,1) * qt(.95, (n1 + n2 -2)) * sp * (1 / n1 + 1 / n2)^.5
n1 <- n2 <- 10
x1 <- 5 ##treated
x2 <- 3  ##placebo
s1 <- 0.68  ##treated
s2 <- 0.60  ##placebo
sp = sqrt( ((n1-1) * s1^2) + ((n2-1) * s2^2) / (n1 + n2 - 2))
x2 - x1 + c(-1,1) * qt(.95, (n1 + n2 -2)) * sp * (1 / n1 + 1 / n2)^.5
n1 <- n2 <- 10
x1 <- 5 ##treated
x2 <- 3  ##placebo
s1 <- 0.68  ##treated
s2 <- 0.60  ##placebo
sp = sqrt( ((n1-1) * s1) + ((n2-1) * s2) / (n1 + n2 - 2))
x2 - x1 + c(-1,1) * qt(.95, (n1 + n2 -2)) * sp * (1 / n1 + 1 / n2)^.5
d1 = c(140, 138, 150, 148, 135)
d2 = c(132, 135, 151, 146, 130)
t.test(d1, d2)
d1 = c(140, 138, 150, 148, 135)
d2 = c(132, 135, 151, 146, 130)
d3 = d2 - d1
t.test(d3)
mn = 1100
s = 30
z = c(qnorm(.05), qnorm(.95))
n = 9
mu0 = mn - z * s / sqrt(nrow(n))
mn = 1100
s = 30
z = c(qnorm(.05), qnorm(.95))
n = 9
mu0 = mn - z * s / sqrt(n)
mu0
round(mu0)
# Treated group
trt.n <- 9
trt.mean <- -3
trt.sd <- 1.5
# Placebo group
plc.n <- 9
plc.mean <- 1
plc.sd <- 1.8
# Calculate t-value
(df <- trt.n + plc.n - 2)
sp <- ((trt.n - 1) * trt.sd^2 + (plc.n - 1) * plc.sd^2) / df
sp
se <- sqrt((1.5^2*8+1.8^2*8)/16 * (1/9 +1/9))
z <- (-3+1) / se
pvalue <- pnorm(z) * 2
pvalue
setwd("~/G_WD/R/machine-learning-ex1")
read.csv("ex1data.txt", header = TRUE)
read.csv("ex1data1.txt")
data1 = read.csv("ex1data1.txt")
str(data1)
colnames(data1) = c('X', 'y')
data1
rm(dat1)
rm(data1)
=======
if( Sys.info()['sysname'] == "Windows"){
setwd("C:/Users/thealy/G_WD/Machine_Learning/R Scripts")
} else {
setwd("~/G_WD/Machine_Learning/R Scripts")
}
## ----------------------------- Single Variable Inputs -------------------------------------------
>>>>>>> c38dea992f681f46bd3bcd848981a6abfee3e7db
dat1 = read.csv('ex1data1.txt')
colnames(dat1) = c('x_1', 'y')
## -------------------------------- Multivariate Inputs -------------------------------------------
dat2 = read.csv('ex1data2.txt')
colnames(dat2) = c("x_1", "x_2", "y")
## -------------------------------------- Linear Regression ---------------------------------------
Regress = function(dat, input) {
mu = colMeans(dat)
sigma = apply(dat, 2, sd)
dat = t((t(dat) - mu) / sigma)
X = as.matrix(dat[,1:(ncol(dat) - 1)])
X = cbind(x_0 = 1, X)
y = dat$y
m = nrow(X)
iterations = 1500
alpha = 0.01
theta = vector(mode = "numeric",length = ncol(X))
J = function(X, y, theta) {
error_sqr = t(X %*% theta - y) %*% (X %*% theta - y)
(1 / (2 * m)) * error_sqr
}
J_hist = vector()
for( i in 1:iterations){
theta = theta - alpha * (1 / m) * t(t((X %*% theta) - y) %*% X)
J_hist = append(J_hist, J(X, y, theta))
}
plot(J_hist, type = "l")
h_theta = function(input) {
v = c(1, (t(input) - mu) / sigma)
calc = v %*% theta
calc
}
print(c("Thetas:", theta))
print(c("Result:", h_theta(input)))
}
Regress(dat1, 3.5)
if( Sys.info()['sysname'] == "Windows"){
setwd("C:/Users/thealy/G_WD/Machine_Learning/R Scripts")
} else {
setwd("~/G_WD/Machine_Learning/R Scripts")
}
## ----------------------------- Single Variable Inputs -------------------------------------------
dat1 = read.csv('ex1data1.txt')
colnames(dat1) = c('x_1', 'y')
## -------------------------------- Multivariate Inputs -------------------------------------------
dat2 = read.csv('ex1data2.txt')
colnames(dat2) = c("x_1", "x_2", "y")
## -------------------------------------- Linear Regression ---------------------------------------
Regress = function(dat, input) {
mu = colMeans(dat)
sigma = apply(dat, 2, sd)
dat = t((t(dat) - mu) / sigma)
X = as.matrix(dat[,1:(ncol(dat) - 1)])
X = cbind(x_0 = 1, X)
y = dat[, 'y']
m = nrow(X)
iterations = 1500
alpha = 0.01
theta = vector(mode = "numeric",length = ncol(X))
J = function(X, y, theta) {
error_sqr = t(X %*% theta - y) %*% (X %*% theta - y)
(1 / (2 * m)) * error_sqr
}
J_hist = vector()
for( i in 1:iterations){
theta = theta - alpha * (1 / m) * t(t((X %*% theta) - y) %*% X)
J_hist = append(J_hist, J(X, y, theta))
}
plot(J_hist, type = "l")
h_theta = function(input) {
v = c(1, (t(input) - mu) / sigma)
calc = v %*% theta
calc
}
print(c("Thetas:", theta))
print(c("Result:", h_theta(input)))
}
Regress(dat1, 3.5)
Regress(dat2, c(1650, 3))
if( Sys.info()['sysname'] == "Windows"){
setwd("C:/Users/thealy/G_WD/Machine_Learning/R Scripts")
} else {
setwd("~/G_WD/Machine_Learning/R Scripts")
}
## ----------------------------- Single Variable Inputs -------------------------------------------
dat1 = read.csv('ex1data1.txt')
colnames(dat1) = c('x_1', 'y')
## -------------------------------- Multivariate Inputs -------------------------------------------
dat2 = read.csv('ex1data2.txt')
colnames(dat2) = c("x_1", "x_2", "y")
## -------------------------------------- Linear Regression ---------------------------------------
Regress = function(dat, input) {
mu = colMeans(dat)
sigma = apply(dat, 2, sd)
dat = t((t(dat) - mu) / sigma)
X = as.matrix(dat[,1:(ncol(dat) - 1)])
X = cbind(x_0 = 1, X)
y = dat[, 'y']
m = nrow(X)
iterations = 1500
alpha = 0.01
theta = vector(mode = "numeric",length = ncol(X))
J = function(X, y, theta) {
error_sqr = t(X %*% theta - y) %*% (X %*% theta - y)
(1 / (2 * m)) * error_sqr
}
J_hist = vector()
for( i in 1:iterations){
theta = theta - alpha * (1 / m) * t(t((X %*% theta) - y) %*% X)
J_hist = append(J_hist, J(X, y, theta))
}
plot(J_hist, type = "l")
h_theta = function(input) {
v = c(1, (t(input) - mu[1:ncol(X)]) / sigma[1:ncol(X)])
calc = v %*% theta
calc
}
print(c("Thetas:", theta))
print(c("Result:", h_theta(input)))
}
Regress(dat1, 3.5)
Regress(dat2, c(1650, 3))
Regress = function(dat, input) {
mu = colMeans(dat)
sigma = apply(dat, 2, sd)
dat = t((t(dat) - mu) / sigma)
X = as.matrix(dat[,1:(ncol(dat) - 1)])
X = cbind(x_0 = 1, X)
y = dat[, 'y']
m = nrow(X)
iterations = 1500
alpha = 0.01
theta = vector(mode = "numeric",length = ncol(X))
J = function(X, y, theta) {
error_sqr = t(X %*% theta - y) %*% (X %*% theta - y)
(1 / (2 * m)) * error_sqr
}
J_hist = vector()
for( i in 1:iterations){
theta = theta - alpha * (1 / m) * t(t((X %*% theta) - y) %*% X)
J_hist = append(J_hist, J(X, y, theta))
}
plot(J_hist, type = "l")
h_theta = function(input) {
v = c(1, (t(input) - mu[1:(ncol(X) - 1)]) / sigma[1:(ncol(X)-1)])
calc = v %*% theta
calc
}
print(c("Thetas:", theta))
print(c("Result:", h_theta(input)))
}
Regress(dat1, 3.5)
Regress(dat2, c(1650, 3))
if( Sys.info()['sysname'] == "Windows"){
setwd("C:/Users/thealy/G_WD/Machine_Learning/R Scripts")
} else {
setwd("~/G_WD/Machine_Learning/R Scripts")
}
## ----------------------------- Single Variable Inputs -------------------------------------------
dat1 = read.csv('ex1data1.txt')
colnames(dat1) = c('x_1', 'y')
## -------------------------------- Multivariate Inputs -------------------------------------------
dat2 = read.csv('ex1data2.txt')
colnames(dat2) = c("x_1", "x_2", "y")
## -------------------------------------- Linear Regression ---------------------------------------
Regress = function(dat, input) {
mu = colMeans(dat)
sigma = apply(dat, 2, sd)
dat = t((t(dat) - mu) / sigma)
X = as.matrix(dat[,1:(ncol(dat) - 1)])
X = cbind(x_0 = 1, X)
y = dat[, 'y']
m = nrow(X)
iterations = 1500
alpha = 0.01
theta = vector(mode = "numeric",length = ncol(X))
J = function(X, y, theta) {
error_sqr = t(X %*% theta - y) %*% (X %*% theta - y)
(1 / (2 * m)) * error_sqr
}
J_hist = vector()
for( i in 1:iterations){
theta = theta - alpha * (1 / m) * t(t((X %*% theta) - y) %*% X)
J_hist = append(J_hist, J(X, y, theta))
}
plot(J_hist, type = "l")
<<<<<<< HEAD
theta
setwd("~/G_WD/R/machine-learning-ex1")
dat1 = read.csv('ex1data1.txt')
colnames(dat1) = c('x_1', 'y')
dat1 = cbind(x_0 = 1, dat1)
X = dat1[,1:2]
y = dat1$y
m = length(X)
iterations = 1500
alpha = 0.01
theta = vector(mode = "numeric",length = 2)
J = function(X, y, theta) {
h = X * theta
error = h - y
error_sqr = error^2
1 / (2 * m) * sum(error_sqr)
}
J_hist = vector()
for( i in 1:iterations){
h = X * theta
errors = h - y
theta_change = (alpha / m) * t(X) * errors
theta = theta - theta_change
J_hist = append(J_hist, J(X, y, theta))
}
J_hist
plot(J_hist, type = "l")
theta
J = function(X, y, theta) {
h = X * theta
error = h - y
error_sqr = error^2
1 / (2 * m) * sum(error_sqr)
}
J
J(X, y, theta)
setwd("~/G_WD/R/machine-learning-ex1")
dat1 = read.csv('ex1data1.txt')
colnames(dat1) = c('x_1', 'y')
dat1 = cbind(x_0 = 1, dat1)
X = dat1[,1:2]
y = dat1$y
m = length(X)
iterations = 1500
alpha = 0.01
theta = vector(mode = "numeric",length = 2)
J = function(X, y, theta) {
h = X * theta
error = h - y
error_sqr = error^2
1 / (2 * m) * sum(error_sqr)
}
getwd()
J(X, y, theta)
theta
h = X * theta
h
sum(X) * theta
J = function(X, y, theta) {
h = sum(X) * theta
error = h - y
error_sqr = error^2
1 / (2 * m) * sum(error_sqr)
}
J(X, y, theta)
J_hist = vector()
for( i in 1:iterations){
h = sum(X) * theta
errors = h - y
theta_change = (alpha / m) * t(X) * errors
theta = theta - theta_change
J_hist = append(J_hist, J(X, y, theta))
}
J_hist
dat1 = read.csv('ex1data1.txt')
colnames(dat1) = c('x_1', 'y')
dat1 = cbind(x_0 = 1, dat1)
X = dat1[,1:2]
y = dat1$y
m = length(X)
iterations = 1500
alpha = 0.01
theta = vector(mode = "numeric",length = 2)
J = function(X, y, theta) {
h = sum(X * theta)
error = h - y
error_sqr = error^2
1 / (2 * m) * sum(error_sqr)
}
J(X, y, theta)
h
theta
X
sum(X * theta)
X * theta
X %*% theta
X = as.matrix(dat1[,1:2])
y = as.vector(dat1$y)
X %*% theta
h = X %*% theta
h - y
error = h - y
error ^2
dat1 = read.csv('ex1data1.txt')
colnames(dat1) = c('x_1', 'y')
dat1 = cbind(x_0 = 1, dat1)
X = as.matrix(dat1[,1:2])
y = as.vector(dat1$y)
m = length(X)
iterations = 1500
alpha = 0.01
theta = vector(mode = "numeric",length = 2)
J = function(X, y, theta) {
h = X %*% theta
error = h - y
error_sqr = error^2
1 / (2 * m) * sum(error_sqr)
}
J(X, y, theta)
J_hist = vector()
for( i in 1:iterations){
h = sum(X %*% theta)
errors = h - y
theta_change = (alpha / m) * t(X) * errors
theta = theta - theta_change
J_hist = append(J_hist, J(X, y, theta))
}
plot(J_hist, type = "l")
J
J_hist
X = as.matrix(dat1[,1:2])
y = as.vector(dat1$y)
m = length(X)
iterations = 1500
alpha = 0.01
theta = vector(mode = "numeric",length = 2)
J = function(X, y, theta) {
h = X %*% theta
error = h - y
error_sqr = error^2
1 / (2 * m) * sum(error_sqr)
}
J_hist = vector()
for( i in 1:iterations){
h = sum(X %*% theta)
errors = h - y
theta_change = (alpha / m) * t(X) %*% errors
theta = theta - theta_change
J_hist = append(J_hist, J(X, y, theta))
}
plot(J_hist, type = "l")
for( i in 1:iterations){
h = sum(X %*% theta)
errors = h - y
theta_change = (alpha / m) * t(X) %*% errors
theta = theta - theta_change
J_hist = append(J_hist, J(X, y, theta))
}
J_hist
h
X = as.matrix(dat1[,1:2])
y = as.vector(dat1$y)
m = length(X)
iterations = 1500
alpha = 0.01
theta = vector(mode = "numeric",length = 2)
J = function(X, y, theta) {
h = X %*% theta
error = h - y
error_sqr = error^2
1 / (2 * m) * sum(error_sqr)
}
J(X, y, theta)
J_hist = vector()
for( i in 1:iterations){
h = X %*% theta
errors = h - y
theta_change = (alpha / m) * (t(X) %*% errors)
theta = theta - theta_change
J_hist = append(J_hist, J(X, y, theta))
}
plot(J_hist, type = "l")
theta
theta[1]
dat1 = read.csv('ex1data1.txt')
colnames(dat1) = c('x_1', 'y')
dat1 = cbind(x_0 = 1, dat1)
X = as.matrix(dat1[,1:2])
y = as.vector(dat1$y)
m = length(X)
iterations = 1500
alpha = 0.1
theta = vector(mode = "numeric",length = 2)
J = function(X, y, theta) {
h = X %*% theta
error = h - y
error_sqr = error^2
1 / (2 * m) * sum(error_sqr)
}
J_hist = vector()
for( i in 1:iterations){
h = X %*% theta
errors = h - y
theta_change = (alpha / m) * (t(X) %*% errors)
theta = theta - theta_change
J_hist = append(J_hist, J(X, y, theta))
}
plot(J_hist, type = "l")
dat1 = read.csv('ex1data1.txt')
colnames(dat1) = c('x_1', 'y')
dat1 = cbind(x_0 = 1, dat1)
X = as.matrix(dat1[,1:2])
y = as.vector(dat1$y)
m = length(X)
iterations = 1500
alpha = 0.05
theta = vector(mode = "numeric",length = 2)
J = function(X, y, theta) {
h = X %*% theta
error = h - y
error_sqr = error^2
1 / (2 * m) * sum(error_sqr)
}
J_hist = vector()
for( i in 1:iterations){
h = X %*% theta
errors = h - y
theta_change = (alpha / m) * (t(X) %*% errors)
theta = theta - theta_change
J_hist = append(J_hist, J(X, y, theta))
}
plot(J_hist, type = "l")
dat1 = read.csv('ex1data1.txt')
colnames(dat1) = c('x_1', 'y')
dat1 = cbind(x_0 = 1, dat1)
X = as.matrix(dat1[,1:2])
y = as.vector(dat1$y)
m = length(X)
iterations = 1500
alpha = 0.01
theta = vector(mode = "numeric",length = 2)
J = function(X, y, theta) {
h = X %*% theta
error = h - y
error_sqr = error^2
1 / (2 * m) * sum(error_sqr)
}
J_hist = vector()
for( i in 1:iterations){
h = X %*% theta
errors = h - y
theta_change = (alpha / m) * (t(X) %*% errors)
theta = theta - theta_change
J_hist = append(J_hist, J(X, y, theta))
}
plot(J_hist, type = "l")
print("Thetas found by gradient descent:", print(theta))
print("Thetas found by gradient descent:"); print(theta))
print("Thetas found by gradient descent:"); print(theta)
plot(J_hist, type = "l")
print("Thetas found by gradient descent:");
print(theta)
paste(print("Thetas found by gradient descent:"), print(theta) )
plot(J_hist, type = "l")
paste(print("Theta_0 found by gradient descent:"), print(theta[1]) )
paste(print("Theta_1 found by gradient descent:"), print(theta[2]) )
paste(print("Theta_0 found by gradient descent: "), print(theta[1]) )
paste(print("Theta_1 found by gradient descent: "), print(theta[2]) )
plot(J_hist, type = "l")
paste(print("Theta_0 found by gradient descent: "), print(theta[1]) )
paste(print("Theta_0 found by gradient descent: "), print(theta[1]) )
paste(c("Theta_0 found by gradient descent: "), theta[1] )
paste(c("Theta_0 found by gradient descent:"), theta[1] )
paste(c("Theta_0 found by gradient descent:"), theta[1] )
paste(c("Theta_1 found by gradient descent:"), theta[2] )
predict1 = [1, 3.5] %*% theta
predict1 = vector(1, 3.5) %*% theta
matrix(1, 3.5)
vector(1, 3.5)
numeric(1, 3.5)
vector(mode = "numeric", length = 2)
vars = vector(mode = "numeric", length = 2)
vars = numeric(1, 3.5)
vars[1] = 1
vars[2] = 3.5
vars
vars %*% theta
predict1 = vars %*% theta
predict1 * 10000
errors
t(X) %*% errors
=======
h_theta = function(input) {
v = c(1, input)
calc = v %*% theta
calc
}
print(c("Thetas:", theta))
print(c("Result:", h_theta(input)))
}
Regress(dat1, 3.5)
Regress(dat2, c(1650, 3))
>>>>>>> c38dea992f681f46bd3bcd848981a6abfee3e7db
